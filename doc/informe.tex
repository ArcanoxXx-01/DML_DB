\section{DML}\label{dml}

\subsection{Introducción}\label{introducciuxf3n}

\textbf{DML} (\emph{Distributed Machine Learning}): es un sistema que
permite a los usuarios entrenar modelos de machine learning de forma
distribuida y realizar predicciones utilizando modelos previamente
entrenados.

El sistema expone una \textbf{API REST} que ofrece los servicios de
entrenamiento y predicción, y además incluye una aplicación de consola
que encapsula toda la lógica necesaria para que el funcionamiento del
sistema sea completamente transparente para el usuario.

\subsection{Alcance del Sistema}\label{alcance-del-sistema}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  El sistema ofrece diversos modelos de machine learning para tareas de
  \textbf{\emph{regresión}} y \textbf{\emph{clasificación.}}
\item
  Permite a los usuarios subir archivos ****.csv**** con los datasets de
  entrenamiento y predicción.
\item
  Los usuarios pueden crear procesos de entrenamiento indicando:

  \begin{itemize}
  \tightlist
  \item
    el tipo de entrenamiento (regresión o clasificación).
  \item
    el dataset que se usará.
  \item
    los modelos a entrenar.
  \end{itemize}
\item
  El sistema permite consultar el estado de los entrenamientos en curso.
\item
  Los usuarios pueden ejecutar predicciones utilizando modelos
  previamente entrenados.
\item
  Se pueden consultar los resultados generados por las predicciones.
\item
  Los usuarios pueden descargar los modelos ya entrenados.
\end{enumerate}

\subsection{Arquitectura y Características
Técnicas}\label{arquitectura-y-caracteruxedsticas-tuxe9cnicas}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  El sistema utiliza una arquitectura modular y desacoplada basada en
  dos tipos de nodos: \textbf{Workers} y \textbf{DataBase}.
\item
  Es tolerante a fallas de hasta dos nodos, independientemente de su
  tipo.
\item
  Ofrece escalado horizontal mediante la adición de más workers.
\item
  Garantiza consistencia eventual en los datos distribuidos.
\item
  Tolera divisiones y reconexiones de la red sin afectar su operación
  general.
\end{enumerate}

\subsection{Nodos de Base de Datos (DataBase
Nodes)}\label{nodos-de-base-de-datos-database-nodes}

Los nodos de base de datos actúan como servicios independientes que
exponen una API REST para administrar sus datos locales y responder a
las solicitudes que reciben desde los workers.

Cada nodo mantiene su propio almacenamiento, procesa consultas de
lectura y escritura, y participa en el mecanismo de replicación
distribuida para lograr la consistencia del sistema.

\subsubsection{Almacenamiento Local}\label{almacenamiento-local}

\begin{itemize}
\item
  Los nodos no utilizan bases de datos SQL, sino que toda la información
  se almacena en archivos CSV, lo que simplifica la replicación y el
  manejo distribuido.
\item
  Los datasets no se guardan como un único archivo, sino divididos en
  batches de 64 muestras. Cada batch se almacena como un CSV
  independiente.
\item
  Las relaciones internas del sistema se manejan con dos archivos
  adicionales:

  \begin{itemize}
  \tightlist
  \item
    Un CSV que vincula entrenamientos → datasets, y almacena metdatos de
    los entrenamientos.
  \item
    Un CSV que vincula modelos → entrenamientos, y almacena metdatos de
    los modelos.
  \end{itemize}
\end{itemize}

\subsubsection{Control de Versiones y
Consistencia}\label{control-de-versiones-y-consistencia}

\begin{itemize}
\item
  Cada nodo mantiene una variable de versión asociada a sus datos
  locales. Esta versión permite detectar si un nodo está actualizado o
  si necesita replicar cambios desde otro nodo.
\item
  \textbf{Escrituras}:

  \begin{itemize}
  \tightlist
  \item
    Cuando un nodo recibe una solicitud de escritura, registra el cambio
    localmente y luego reenvía la operación a nodos adicionales.
  \item
    Este proceso se repite hasta lograr la consistencia en toda la red.
  \end{itemize}
\item
  \textbf{Lecturas}:

  Una solicitud de lectura se reenvía a varios nodos, y:

  \begin{itemize}
  \tightlist
  \item
    El sistema devuelve el dato con la versión más reciente.
  \item
    Si un nodo devuelve una versión atrasada o no posee el dato
    requerido, se le ordena actualizarse antes de continuar operando.
  \end{itemize}
\end{itemize}

\subsubsection{Tolerancia a Fallos, Particiones y
Reconexiones}\label{tolerancia-a-fallos-particiones-y-reconexiones}

El diseño distribuido permite que la red siga operativa incluso si
algunos nodos fallan o se desconectan temporalmente. Cuando un nodo
vuelve a conectarse, compara su versión local y sincroniza
automáticamente los datos pendientes.

\subsubsection{Tolerancia a Particiones de
Red}\label{tolerancia-a-particiones-de-red}

El sistema soporta particiones de red sin detener el funcionamiento:

\begin{itemize}
\item
  Cada partición puede seguir procesando lecturas y escrituras de manera
  independiente.
\item
  No existe un nodo central cuya caída detenga el sistema.
\end{itemize}

Además, debido a la forma en que se realizan los entrenamientos:

\begin{itemize}
\item
  Las iteraciones del entrenamiento avanzan secuencialmente sobre los
  batches.
\item
  Si ocurre una partición, cada subred sigue entrenando el modelo por su
  cuenta, incrementando su versión en cada iteración.
\item
  Al reconectarse la red, los nodos comparan versiones:

  \begin{itemize}
  \tightlist
  \item
    La versión más alta corresponde al modelo que más iteraciones
    realizó,
  \item
    y se asume como mejor, por lo que el resto de nodos se actualizan a
    esa versión.
  \end{itemize}
\end{itemize}

Este mecanismo garantiza que después de una partición y su posterior
reconexión, el sistema siempre converge hacia el modelo más avanzado sin
generar conflictos.

\subsubsection{Reconexión y Consistencia
Eventual}\label{reconexiuxf3n-y-consistencia-eventual}

Cuando la red vuelve a unificarse:

\begin{itemize}
\item
  Los nodos intercambian sus versiones actuales.
\item
  Los nodos desactualizados recuperan los datos de la versión más
  reciente mediante el proceso de replicación.
\item
  El sistema converge automáticamente hacia un estado consistente.
\end{itemize}

Con esta estrategia, el sistema asegura consistencia eventual, incluso
bajo fallos, divisiones temporales de la red y reconexiones posteriores.

\subsection{Nodos Worker}\label{nodos-worker}

Los nodos Worker son responsables de procesar las peticiones de los
usuarios y ejecutar las tareas de entrenamiento y predicción de los
modelos.

Cada worker funciona de forma totalmente independiente, sin necesidad de
comunicarse ni coordinarse con otros workers. Su única interacción es
con los nodos DataBase, que actúan como fuente de datos y como mecanismo
de control del trabajo distribuido.

\subsubsection{Funciones Principales:}\label{funciones-principales}

\textbf{1. Recepción de solicitudes del usuario}:

Cada worker expone una API REST que le permite a los clientes:

\begin{itemize}
\tightlist
\item
  Subir datasets.
\item
  Crear entrenamientos.
\item
  Consultar estado y resultados de entrenamientos.
\item
  Crear predicciones.
\item
  Consultar estado y resultados de predicciones.
\item
  Descargar modelos entrenados.
\end{itemize}

\textbf{2. Orquestación de tareas}:

Los workers coordinan cada operación enviando las solicitudes necesarias
a los nodos DataBase y ejecutando la lógica interna del entrenamiento o
la predicción.

\textbf{3. Entrenamiento y predicción de modelos}:

Los workers realizan:

\begin{itemize}
\tightlist
\item
  Descarga de los batches de datos desde los nodos DB.
\item
  Entrenamiento secuencial del modelo batch por batch.
\item
  Actualización continua del estado y progreso en los nodos DB.
\item
  Guardado del modelo entrenado al finalizar.
\item
  Ejecución de predicciones utilizando modelos ya entrenados.
\end{itemize}

\subsubsection{Independencia entre
Workers}\label{independencia-entre-workers}

Los workers no conocen ni necesitan conocer la existencia de otros
workers. No comparten estado ni intercambian mensajes.

Esta independencia permite escalar horizontalmente simplemente agregando
nuevos nodos.

\subsubsection{Mecanismo de Control y Asignación de Trabajo (Campo
health)}\label{mecanismo-de-control-y-asignaciuxf3n-de-trabajo-campo-health}

Para evitar que dos workers entrenen o predigan sobre el mismo modelo al
mismo tiempo, el sistema utiliza un mecanismo de heartbeat basado en un
campo llamado \textbf{\emph{health}}, almacenado en los nodos DataBase.

\paragraph{Su funcionamiento es el
siguiente:}\label{su-funcionamiento-es-el-siguiente}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Selección del modelo disponible}:

  \begin{itemize}
  \tightlist
  \item
    Los nodos DataBase llevan un registro del health de cada modelo.
  \item
    Un worker puede solicitar al DB un modelo cuyo health sea de hace
    más de 20 segundos (Ese modelo se considera libre o abandonado).
  \end{itemize}
\item
  \textbf{Heartbeat del worker}:

  \begin{itemize}
  \tightlist
  \item
    Una vez que un worker toma un modelo, envía cada 10 segundos una
    señal al DB informando que sigue activo.
  \item
    El DB actualiza (health = instante\_actual)
  \end{itemize}
\item
  \textbf{Detección de fallo o abandono}:

  \begin{itemize}
  \tightlist
  \item
    Si no se recibe un heartbeat en más de 20 segundos, el DB considera
    que:

    \begin{itemize}
    \tightlist
    \item
      El worker falló, o
    \item
      El worker se desconectó, o
    \item
      El worker finalizó sin reportarlo correctamente.
    \end{itemize}
  \item
    Ese modelo vuelve a estar disponible para que otro worker lo tome.
  \end{itemize}
\item
  \textbf{Reasignación automática}:

  \begin{itemize}
  \tightlist
  \item
    Cualquier worker que pida un modelo libre podrá tomarlo
    inmediatamente.
  \item
    No se necesitan bloqueos distribuidos ni coordinación entre workers.
  \end{itemize}
\end{enumerate}

\subsubsection{Ventajas del Mecanismo:}\label{ventajas-del-mecanismo}

\begin{itemize}
\tightlist
\item
  Evita conflictos: ningún modelo será entrenado por dos workers
  simultáneamente.
\item
  Alta disponibilidad: si un worker se cae, el trabajo se reasigna
  automáticamente.
\item
  Escalabilidad simple: más workers = más capacidad de entrenamiento sin
  cambios estructurales.
\item
  Desac acoplamiento total: la lógica distribuida se delega a los nodos
  DB mediante el campo health.
\end{itemize}

\subsection{Descubrimiento de Nodos}\label{descubrimiento-de-nodos}

Para que cada nodo del sistema pueda localizar a otros nodos activos
dentro de la red, se utilizan dos mecanismos de descubrimiento
complementarios. Esto garantiza que, si uno falla, el otro pueda actuar
como respaldo, manteniendo la comunicación y la operatividad del
sistema.

\subsubsection{Domain Name Service (DNS)}\label{domain-name-service-dns}

El sistema se ejecuta sobre una red de Docker utilizando Docker Swarm,
que proporciona un DNS interno capaz de resolver automáticamente los
nombres de servicio de cada nodo.

Gracias a este DNS:

\begin{itemize}
\tightlist
\item
  Los nodos no necesitan conocer direcciones IP específicas.
\item
  Un worker puede comunicarse con los nodos DataBase simplemente usando
  su dominio o nombre de servicio.
\item
  Docker gestiona la resolución y el balanceo entre instancias activas.
\item
  Los fallos de nodos individuales quedan aislados del resto del
  sistema.
\item
  Este mecanismo es la forma principal de descubrimiento dentro de la
  red.
\end{itemize}

\subsubsection{IP Cache}\label{ip-cache}

Como mecanismo de respaldo, cada nodo mantiene una caché local de
direcciones IP correspondientes a otros nodos conocidos. Esta técnica
funciona incluso si la resolución por DNS falla.

\subsubsection{El funcionamiento es el
siguiente:}\label{el-funcionamiento-es-el-siguiente}

\textbf{IPs fijas al iniciar el nodo:}

Cuando un nodo se levanta, carga en su caché un conjunto de IPs fijas
preconfiguradas. Esto le permite tener acceso inmediato a nodos
potenciales, incluso si el DNS presenta fallos desde el inicio.

\textbf{Actualización dinámica:}

A medida que el nodo interactúa con otros, añade nuevas IPs a la caché
cuando detecta nodos que responden correctamente.

\textbf{Uso como respaldo:}

Si el DNS no funciona o la red presenta inconsistencias, el nodo
reutiliza las IPs guardadas en la caché para intentar conectarse a otros
nodos activos.

\textbf{Depuración automática:}

Si una IP en la caché deja de ser válida, se descarta al detectar fallos
consecutivos.

Gracias a esta combinación, el sistema puede arrancar, operar y
recuperarse incluso en momentos donde la infraestructura de red esté
parcialmente degradada.

\subsection{Comunicación entre Nodos}\label{comunicaciuxf3n-entre-nodos}

La comunicación entre todos los componentes del sistema (workers, nodos
DataBase y clientes) se realiza exclusivamente mediante peticiones HTTP.

Cada nodo expone una API REST que permite intercambiar datos y coordinar
las operaciones distribuidas sin necesidad de mantener conexiones
persistentes.

Gracias a este enfoque, los nodos se mantienen desacoplados, pueden
operar de forma independiente y es posible reemplazarlos, escalarlos o
reiniciarlos sin afectar el funcionamiento global del sistema.
